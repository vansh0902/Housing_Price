This repository exclusively includes the Kaggle notebook utilized for the 'Housing Prices Competition.' In this project, the dataset containing over 75 features related to housing was subjected to pre-processing and feature engineering to facilitate predicting housing prices accurately. The preprocessing involved crucial steps such as feature scaling, one-hot encoding, and ordinal encoding for the selected significant features, as determined from the heatmap analysis.

Various predictive models were employed to achieve the best results. Notably, Decision Trees, Random Forest Regressor, and XGBoost were utilized to train the data and make predictions. The final model achieved a Mean Absolute Error (MAE) of 16495, indicating the level of accuracy in price prediction.

Additionally, a pipeline for data pre-processing and implementing the XGBoost model was created, streamlining the process and making it more efficient.
